{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e47d3243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank(G, alpha=0.85, personalization=None, max_iter=100, tol=1.0e-6, nstart=None, weight='weight', dangling=None):\n",
    "    if len(G) == 0: \n",
    "        return {} \n",
    "  \n",
    "    if not G.is_directed(): \n",
    "        D = G.to_directed() \n",
    "    else: \n",
    "        D = G\n",
    "        \n",
    "    # Create a copy in (right) stochastic form \n",
    "    W = nx.stochastic_graph(D, weight=weight) \n",
    "    N = W.number_of_nodes()\n",
    "    \n",
    "    # Choose fixed starting vector if not given \n",
    "    if nstart is None: \n",
    "        x = dict.fromkeys(W, 1.0 / N) \n",
    "    else: \n",
    "        # Normalized nstart vector \n",
    "        s = float(sum(nstart.values())) \n",
    "        x = dict((k, v / s) for k, v in nstart.items()) \n",
    "        \n",
    "    if personalization is None:\n",
    "        # Assign uniform personalization vector if not given \n",
    "        p = dict.fromkeys(W, 1.0 / N)\n",
    "    else: \n",
    "        missing = set(G) - set(personalization) \n",
    "        if missing: \n",
    "            raise NetworkXError('Personalization dictionary must have a value for every node. Missing nodes %s' % missing) \n",
    "        s = float(sum(personalization.values())) \n",
    "        p = dict((k, v / s) for k, v in personalization.items())\n",
    "        \n",
    "    if dangling is None:\n",
    "        # Use personalization vector if dangling vector not specified \n",
    "        dangling_weights = p \n",
    "    else: \n",
    "        missing = set(G) - set(dangling) \n",
    "        if missing: \n",
    "            raise NetworkXError('Dangling node dictionary must have a value for every node. Missing nodes %s' % missing) \n",
    "        s = float(sum(dangling.values())) \n",
    "        dangling_weights = dict((k, v/s) for k, v in dangling.items())\n",
    "        \n",
    "    dangling_nodes = [n for n in W if W.out_degree(n, weight=weight) == 0.0]\n",
    "    \n",
    "     # power iteration: make up to max_iter iterations \n",
    "    for _ in range(max_iter): \n",
    "        xlast = x \n",
    "        x = dict.fromkeys(xlast.keys(), 0) \n",
    "        danglesum = alpha * sum(xlast[n] for n in dangling_nodes) \n",
    "        for n in x:\n",
    "            # this matrix multiply looks odd because it is \n",
    "            # doing a left multiply x^T=xlast^T*W \n",
    "            for nbr in W[n]: \n",
    "                x[nbr] += alpha * xlast[n] * W[n][nbr][weight] \n",
    "            x[n] += danglesum * dangling_weights[n] + (1.0 - alpha) * p[n] \n",
    "  \n",
    "        # check convergence, l1 norm \n",
    "        err = sum([abs(x[n] - xlast[n]) for n in x]) \n",
    "        if err < N*tol: \n",
    "            return x \n",
    "    raise NetworkXError('Pagerank: power iteration failed to converge in %d iterations.' % max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f9359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f391812",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.barabasi_albert_graph(60, 41) \n",
    "pr = nx.pagerank(G, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e76b3c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.028052290070731803, 1: 0.012183016941013425, 2: 0.012570764524140425, 3: 0.012763545911401247, 4: 0.01254385932318987, 5: 0.012759652998990584, 6: 0.013580149000897337, 7: 0.01296869733144541, 8: 0.011397965305089377, 9: 0.01277907870947181, 10: 0.011381972094023467, 11: 0.013182524213139384, 12: 0.01317955393574873, 13: 0.012951334571320501, 14: 0.012943226790270492, 15: 0.013170885047003799, 16: 0.012963450658613972, 17: 0.013381888161762888, 18: 0.013567868533192126, 19: 0.01318370642719815, 20: 0.013370142598196372, 21: 0.01316906159548988, 22: 0.013162622451814869, 23: 0.012973318583988841, 24: 0.013373093877750583, 25: 0.013174393698354447, 26: 0.013170162559553361, 27: 0.013577110996987383, 28: 0.013161806963620282, 29: 0.012969398620647651, 30: 0.012987564119811673, 31: 0.013362044091829381, 32: 0.012977747651273736, 33: 0.01257262343356531, 34: 0.013172186976574202, 35: 0.0127651574249563, 36: 0.012764924081416613, 37: 0.012744778450884097, 38: 0.013778340925491907, 39: 0.012758905432764301, 40: 0.012959752947012416, 41: 0.012764889125639261, 42: 0.027901083209623118, 43: 0.02722887075302422, 44: 0.026416003301884046, 45: 0.026213754880400106, 46: 0.026221949728025933, 47: 0.02586185395364625, 48: 0.02553043315998893, 49: 0.024762515978711284, 50: 0.024714927017562276, 51: 0.024067615559735238, 52: 0.02378229746591256, 53: 0.023526492748112963, 54: 0.023140790882484906, 55: 0.022747887984159575, 56: 0.023151316153848002, 57: 0.02193131893690859, 58: 0.022288732338904098, 59: 0.02129669879080027}\n"
     ]
    }
   ],
   "source": [
    "print(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6439f3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
